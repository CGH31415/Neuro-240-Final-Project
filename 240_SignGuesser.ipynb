{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "240_SignGuesser",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8V-7BuzUCgi"
      },
      "source": [
        "#imports\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pycocotools\n",
        "import torchvision\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import math\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5wsx38S1Z7R"
      },
      "source": [
        "# Strategy: train NN to predict whether a prediction keypoint set\n",
        "# represents the same sign as a GT keypoint set\n",
        "\n",
        "# Input format: Lists of keypoints in image, scaled/padded to 500x500\n",
        "\n",
        "# Note: model architecture adapted from PyTorch tutorial docs: \"Build the Neural Network\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViGrUcwTBcth"
      },
      "source": [
        "#data upload: SL_combined.csv, predictions.txt in inputs/; Sign_Images.zip in root"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsdgFqWMEtAS",
        "outputId": "d0f97381-82bd-403b-f38a-e4e9b8693c76"
      },
      "source": [
        "if not os.path.isdir('Sign_Images'):\n",
        "  !unzip -o Sign_Images.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Sign_Images.zip\n",
            "   creating: Sign_Images/\n",
            "  inflating: Sign_Images/26.0.png    \n",
            "  inflating: Sign_Images/47.1.png    \n",
            "  inflating: Sign_Images/5.0.png     \n",
            "  inflating: Sign_Images/47.0.png    \n",
            "  inflating: Sign_Images/45.0.png    \n",
            "  inflating: Sign_Images/47.2.png    \n",
            "  inflating: Sign_Images/7.0.png     \n",
            "  inflating: Sign_Images/19.0.png    \n",
            "  inflating: Sign_Images/47.3.png    \n",
            "  inflating: Sign_Images/24.0.png    \n",
            "  inflating: Sign_Images/58.0.png    \n",
            "  inflating: Sign_Images/3.0.png     \n",
            "  inflating: Sign_Images/47.7.png    \n",
            "  inflating: Sign_Images/41.1.png    \n",
            "  inflating: Sign_Images/43.3.png    \n",
            "  inflating: Sign_Images/20.0.png    \n",
            "  inflating: Sign_Images/20.1.png    \n",
            "  inflating: Sign_Images/43.2.png    \n",
            "  inflating: Sign_Images/41.0.png    \n",
            "  inflating: Sign_Images/47.6.png    \n",
            "  inflating: Sign_Images/39.0.png    \n",
            "  inflating: Sign_Images/47.4.png    \n",
            "  inflating: Sign_Images/43.0.png    \n",
            "  inflating: Sign_Images/43.1.png    \n",
            "  inflating: Sign_Images/22.0.png    \n",
            "  inflating: Sign_Images/47.5.png    \n",
            "  inflating: Sign_Images/1.0.png     \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/Sign_Images/\n",
            "  inflating: __MACOSX/Sign_Images/._1.0.png  \n",
            "  inflating: Sign_Images/25.1.png    \n",
            "  inflating: Sign_Images/46.2.png    \n",
            "  inflating: Sign_Images/44.0.png    \n",
            "  inflating: Sign_Images/46.3.png    \n",
            "  inflating: Sign_Images/25.0.png    \n",
            "  inflating: Sign_Images/18.0.png    \n",
            "  inflating: Sign_Images/6.0.png     \n",
            "  inflating: Sign_Images/4.0.png     \n",
            "  inflating: Sign_Images/46.1.png    \n",
            "  inflating: Sign_Images/25.2.png    \n",
            "  inflating: Sign_Images/27.0.png    \n",
            "  inflating: Sign_Images/25.3.png    \n",
            "  inflating: Sign_Images/46.0.png    \n",
            "  inflating: Sign_Images/42.0.png    \n",
            "  inflating: Sign_Images/40.2.png    \n",
            "  inflating: Sign_Images/40.3.png    \n",
            "  inflating: Sign_Images/23.0.png    \n",
            "  inflating: Sign_Images/42.1.png    \n",
            "  inflating: Sign_Images/21.0.png    \n",
            "  inflating: Sign_Images/40.1.png    \n",
            "  inflating: Sign_Images/2.0.png     \n",
            "  inflating: Sign_Images/38.1.png    \n",
            "  inflating: Sign_Images/38.0.png    \n",
            "  inflating: Sign_Images/40.0.png    \n",
            "  inflating: Sign_Images/48.4.png    \n",
            "  inflating: Sign_Images/34.0.png    \n",
            "  inflating: Sign_Images/34.1.png    \n",
            "  inflating: Sign_Images/55.0.png    \n",
            "  inflating: Sign_Images/10.0.png    \n",
            "  inflating: Sign_Images/57.0.png    \n",
            "  inflating: Sign_Images/12.0.png    \n",
            "  inflating: Sign_Images/36.0.png    \n",
            "  inflating: Sign_Images/32.0.png    \n",
            "  inflating: Sign_Images/8.1.png     \n",
            "  inflating: Sign_Images/16.1.png    \n",
            "  inflating: Sign_Images/48.2.png    \n",
            "  inflating: Sign_Images/48.3.png    \n",
            "  inflating: Sign_Images/53.0.png    \n",
            "  inflating: Sign_Images/16.0.png    \n",
            "  inflating: Sign_Images/8.0.png     \n",
            "  inflating: Sign_Images/32.1.png    \n",
            "  inflating: Sign_Images/51.0.png    \n",
            "  inflating: Sign_Images/14.0.png    \n",
            "  inflating: Sign_Images/30.1.png    \n",
            "  inflating: Sign_Images/48.1.png    \n",
            "  inflating: Sign_Images/29.0.png    \n",
            "  inflating: Sign_Images/48.0.png    \n",
            "  inflating: Sign_Images/30.0.png    \n",
            "  inflating: Sign_Images/13.0.png    \n",
            "  inflating: Sign_Images/56.0.png    \n",
            "  inflating: Sign_Images/37.0.png    \n",
            "  inflating: Sign_Images/35.0.png    \n",
            "  inflating: Sign_Images/54.1.png    \n",
            "  inflating: Sign_Images/11.0.png    \n",
            "  inflating: Sign_Images/54.0.png    \n",
            "  inflating: Sign_Images/35.1.png    \n",
            "  inflating: Sign_Images/28.4.png    \n",
            "  inflating: Sign_Images/28.0.png    \n",
            "  inflating: Sign_Images/49.1.png    \n",
            "  inflating: Sign_Images/15.0.png    \n",
            "  inflating: Sign_Images/50.0.png    \n",
            "  inflating: Sign_Images/15.1.png    \n",
            "  inflating: Sign_Images/31.0.png    \n",
            "  inflating: Sign_Images/49.0.png    \n",
            "  inflating: Sign_Images/28.1.png    \n",
            "  inflating: Sign_Images/28.3.png    \n",
            "  inflating: Sign_Images/33.0.png    \n",
            "  inflating: Sign_Images/9.0.png     \n",
            "  inflating: __MACOSX/Sign_Images/._9.0.png  \n",
            "  inflating: Sign_Images/17.0.png    \n",
            "  inflating: Sign_Images/52.0.png    \n",
            "  inflating: Sign_Images/28.2.png    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0RO4RPH9soB",
        "outputId": "cfa4457f-8ddd-4268-f08d-58cddc12a581"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm7uPPK96dJ9"
      },
      "source": [
        "class Matcher(nn.Module):\n",
        "    \"\"\"\n",
        "    NN to determine whether the two images match\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Matcher, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(100*6 + 50*6, 512), # X1, Y1, X2, Y2, Score, Label\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        out = self.linear_relu_stack(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVlugmFtEVmZ",
        "outputId": "cd33d9f0-a52a-442b-85d3-c6c12d017145"
      },
      "source": [
        "random_data = torch.rand(1, 150, 6, device=device)\n",
        "model = Matcher()\n",
        "model.to(device)\n",
        "random_result = nn.Softmax(dim = 1)(model(random_data.to(device)))\n",
        "print(random_result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4950, 0.5050]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6vyk2JHKrpx"
      },
      "source": [
        "def strokenum(s):\n",
        "  '''\n",
        "  Converts string labels to integer:\n",
        "  1 = Wedge, 2 = Winkelhaken, 3 = Line\n",
        "\n",
        "  input: s (string, sign label)\n",
        "  '''\n",
        "  if s == \"Wedge\":\n",
        "    return 1\n",
        "  elif s == \"Winkel\":\n",
        "    return 2\n",
        "  elif s == \"Line\":\n",
        "    return 3\n",
        "  else: raise Exception(\"Error: Invalid Stroke\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22W2tBNwAPWw"
      },
      "source": [
        "gt_data = pd.read_csv(\"inputs/SL_combined.csv\")\n",
        "\n",
        "gt_dims = gt_data[[\"hfile\",\"wfile\"]].to_numpy()\n",
        "gt_filenames = gt_data['filename'].to_numpy()\n",
        "gt_labels = np.array([strokenum(s) for s in gt_data['stroke'].to_numpy()])\n",
        "\n",
        "gt_datalen = len(gt_filenames)\n",
        "gt_scores = np.ones([gt_datalen])\n",
        "\n",
        "_sc = 500/np.max(gt_dims, axis=1)\n",
        "gt_scale = np.array([_sc, _sc, _sc, _sc]).T\n",
        "#print(gt_scale)\n",
        "\n",
        "gt_keypoints = np.round(np.multiply(gt_scale, gt_data[['x1','y1','x2','y2']].to_numpy()))\n",
        "#print(np.unique(gt_filenames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcHwFcEkN311"
      },
      "source": [
        "#gt_keypoints[gt_filenames == '19.0.png']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI_Rybg4Jfp2"
      },
      "source": [
        "class SGDataset(object):\n",
        "  def __init__(self, filenames, keypoints, labels, scores):\n",
        "    self.filenames = filenames\n",
        "    self.files_uq = np.unique(filenames)\n",
        "    self.keypoints = keypoints\n",
        "    self.labels = labels\n",
        "    self.scores = scores\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.files_uq)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    \n",
        "    filename = self.files_uq[idx]\n",
        "    filter = self.filenames == filename\n",
        "    \n",
        "\n",
        "    item_keypoints = (self.keypoints[filter]).T\n",
        "    item_labels = self.labels[filter]\n",
        "    item_scores = self.scores[filter]\n",
        "\n",
        "    datalen = len(item_labels)\n",
        "    item_labels = np.reshape(item_labels, [1,datalen])\n",
        "    item_scores = np.reshape(item_scores, [1,datalen])\n",
        "\n",
        "    item = {}\n",
        "    item['filename'] = filename\n",
        "    item['x1'] = item_keypoints[0]\n",
        "    item['y1'] = item_keypoints[1]\n",
        "    item['x2'] = item_keypoints[2]\n",
        "    item['y2'] = item_keypoints[3]\n",
        "    item['labels'] = item_labels\n",
        "    item['scores'] = item_scores\n",
        "\n",
        "    #print(np.shape(item_keypoints), np.shape(item_scores), np.shape(item_labels))\n",
        "    consolidated = np.concatenate([item_keypoints, item_scores, item_labels], axis = 0)\n",
        "    #print(np.shape(consolidated))\n",
        "\n",
        "    return item, consolidated.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM2icl-hP50e",
        "outputId": "5427204d-c1ce-4f5a-e0d7-43e6f1ba9d10"
      },
      "source": [
        "gt_dataset = SGDataset(filenames = gt_filenames,\n",
        "                       keypoints = gt_keypoints,\n",
        "                       labels = gt_labels,\n",
        "                       scores = gt_scores)\n",
        "\n",
        "print(gt_dataset.__len__())\n",
        "\n",
        "print(np.shape(gt_dataset.__getitem__(2)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n",
            "(4, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RzWS-VnUeu9",
        "outputId": "d82f4093-ae2d-4488-bcb9-3ef3fed93762"
      },
      "source": [
        "with open(\"inputs/stroke_predictions_20210505_1819.txt\", \"rb\") as fp:   # Unpickling\n",
        "   training_stroke_predictions = pickle.load(fp)\n",
        "\n",
        "training_stroke_predictions[0].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['name', 'dim', 'scores', 'keypoints', 'labels', 'gtkeypoints', 'gtlabels'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rrK9GQYW44w",
        "outputId": "c97a4d9d-d218-4052-c1a4-6da63096c012"
      },
      "source": [
        "print(np.shape(training_stroke_predictions[0]['keypoints']))\n",
        "print(training_stroke_predictions[0]['keypoints'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11, 17, 3)\n",
            "[[ 82.2054   257.03955    1.      ]\n",
            " [411.76453  254.54909    1.      ]\n",
            " [181.44763  258.28482    1.      ]\n",
            " [134.63525  259.53006    1.      ]\n",
            " [407.3954   254.54909    1.      ]\n",
            " [ 82.82956  257.03955    1.      ]\n",
            " [173.95767  255.79434    1.      ]\n",
            " [407.3954   250.81335    1.      ]\n",
            " [161.47437  253.30383    1.      ]\n",
            " [160.85019  259.53006    1.      ]\n",
            " [148.99106  253.30383    1.      ]\n",
            " [137.75609  262.02054    1.      ]\n",
            " [408.64374  253.30383    1.      ]\n",
            " [109.668655 254.54909    1.      ]\n",
            " [174.58183  254.54909    1.      ]\n",
            " [109.668655 262.02054    1.      ]\n",
            " [127.769455 258.28482    1.      ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfCbuuX-UcpH",
        "outputId": "03681e67-fc12-46ba-d323-2d0584970ddf"
      },
      "source": [
        "pred_filenames = []\n",
        "pred_keypoints = []\n",
        "pred_labels = []\n",
        "pred_scores = []\n",
        "\n",
        "for pred in training_stroke_predictions:\n",
        "  pred_num_strokes = len(pred['labels'])\n",
        "  pred_filenames.append(np.repeat(pred['name'], pred_num_strokes))\n",
        "  pred_keypoints.append(pred['keypoints'][:,:2,:2])\n",
        "  pred_labels.append(pred['labels'])\n",
        "  pred_scores.append(pred['scores'])\n",
        "\n",
        "# print((pred_keypoints[0]))\n",
        "\n",
        "pred_filenames = np.concatenate(pred_filenames)\n",
        "pred_keypoints = np.concatenate(pred_keypoints)\n",
        "pred_labels = np.concatenate(pred_labels)\n",
        "pred_scores = np.concatenate(pred_scores)\n",
        "\n",
        "# print(np.shape(pred_keypoints))\n",
        "pred_keypoints = np.reshape(pred_keypoints, [len(pred_keypoints),4])\n",
        "# print(np.shape(pred_keypoints))\n",
        "\n",
        "assert (len(pred_filenames) == len(pred_keypoints))\n",
        "assert (len(pred_filenames) == len(pred_labels))\n",
        "assert (len(pred_filenames) == len(pred_scores))\n",
        "\n",
        "print(np.shape(pred_scores))\n",
        "\n",
        "print(f'Filenames ({len(pred_filenames)}): {pred_filenames}')\n",
        "print(f'UQFilenames ({len(np.unique(pred_filenames))}): {np.unique(pred_filenames)}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7723,)\n",
            "Filenames (7723): ['1.0' '1.0' '1.0' ... '9.0' '9.0' '9.0']\n",
            "UQFilenames (98): ['1.0' '10.0' '11.0' '12.0' '13.0' '14.0' '15.0' '15.1' '16.0' '16.1'\n",
            " '17.0' '18.0' '19.0' '2.0' '20.0' '20.1' '21.0' '22.0' '23.0' '24.0'\n",
            " '25.0' '25.1' '25.2' '25.3' '26.0' '27.0' '28.0' '28.1' '28.2' '28.3'\n",
            " '28.4' '29.0' '3.0' '30.0' '30.1' '31.0' '32.0' '32.1' '33.0' '34.0'\n",
            " '34.1' '35.0' '35.1' '36.0' '37.0' '38.0' '38.1' '39.0' '4.0' '40.0'\n",
            " '40.1' '40.2' '40.3' '41.0' '41.1' '42.0' '42.1' '43.0' '43.1' '43.2'\n",
            " '43.3' '44.0' '45.0' '46.0' '46.1' '46.2' '46.3' '47.0' '47.1' '47.2'\n",
            " '47.3' '47.4' '47.5' '47.6' '47.7' '48.0' '48.1' '48.2' '48.3' '48.4'\n",
            " '49.0' '49.1' '5.0' '50.0' '51.0' '52.0' '53.0' '54.0' '54.1' '55.0'\n",
            " '56.0' '57.0' '58.0' '6.0' '7.0' '8.0' '8.1' '9.0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiE66BTfRmT7",
        "outputId": "e97a3b44-2ebb-4a80-812a-ff762aa40712"
      },
      "source": [
        "# with open(\"inputs/eval_predictions\", \"rb\") as fp:   # Unpickling\n",
        "#    eval_predictions = pickle.load(fp)\n",
        "\n",
        "# eval_predictions[0].keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['name', 'dim', 'scores', 'keypoints', 'labels'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcLxeHr4RdS8",
        "outputId": "ec65a904-7ec5-408b-920a-3a651a0632b8"
      },
      "source": [
        "# eval_filenames = []\n",
        "# eval_keypoints = []\n",
        "# eval_labels = []\n",
        "# eval_scores = []\n",
        "\n",
        "# for pred in eval_predictions:\n",
        "#   eval_num_strokes = len(pred['labels'])\n",
        "#   eval_filenames.append(np.repeat(pred['name'], eval_num_strokes))\n",
        "#   eval_keypoints.append(pred['keypoints'][:,:2,:2])\n",
        "#   eval_labels.append(pred['labels'])\n",
        "#   eval_scores.append(pred['scores'])\n",
        "\n",
        "# # print((pred_keypoints[0]))\n",
        "\n",
        "# eval_filenames = np.concatenate(eval_filenames)\n",
        "# eval_keypoints = np.concatenate(eval_keypoints)\n",
        "# eval_labels = np.concatenate(eval_labels)\n",
        "# eval_scores = np.concatenate(eval_scores)\n",
        "\n",
        "# # print(np.shape(pred_keypoints))\n",
        "# eval_keypoints = np.reshape(eval_keypoints, [len(eval_keypoints),4])\n",
        "# # print(np.shape(pred_keypoints))\n",
        "\n",
        "\n",
        "# assert (len(eval_filenames) == len(eval_keypoints))\n",
        "# assert (len(eval_filenames) == len(eval_labels))\n",
        "# assert (len(eval_filenames) == len(eval_scores))\n",
        "\n",
        "# print(f'Filenames: ({len(eval_filenames)})')\n",
        "# print(f'UQFilenames ({len(np.unique(eval_filenames))}): {np.unique(eval_filenames)}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filenames: (448)\n",
            "UQFilenames (5): ['Eval1.png' 'Eval2.png' 'Eval3.png' 'Eval4.png' 'Eval5.png']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQsQ8MQYXkEm",
        "outputId": "a4ed412e-aa2a-451a-a021-a670348e8114"
      },
      "source": [
        "pred_dataset = SGDataset(filenames = pred_filenames,\n",
        "                         keypoints = pred_keypoints,\n",
        "                         labels = pred_labels,\n",
        "                         scores = pred_scores)\n",
        "\n",
        "print(pred_dataset.__len__())\n",
        "print(np.shape(pred_dataset.__getitem__(6)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98\n",
            "(51, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6rOcuebSLCU",
        "outputId": "6db36fe7-8a12-48ad-ae1b-b8e9cb74596e"
      },
      "source": [
        "# eval_dataset = SGDataset(filenames = eval_filenames,\n",
        "#                          keypoints = eval_keypoints,\n",
        "#                          labels = eval_labels,\n",
        "#                          scores = eval_scores)\n",
        "\n",
        "# print(eval_dataset.__len__())\n",
        "# print(np.shape(eval_dataset.__getitem__(0)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "(75, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHvRPCCYb8vr"
      },
      "source": [
        "#tool for generating training set\n",
        "def indexbool(a):\n",
        "  out = np.empty(len(a), dtype=bool)\n",
        "  for i in range(len(a)):\n",
        "    if i == 0:\n",
        "      out[i] = True\n",
        "    else:\n",
        "      out[i] = math.floor(float(a[i])) != math.floor(float(a[i-1]))\n",
        "  return out\n",
        "\n",
        "uqfilenames = np.unique(pred_filenames)\n",
        "unique_sign_indices = indexbool(a = uqfilenames)\n",
        "\n",
        "# print(len(unique_sign_indices))\n",
        "# print(len(uqfilenames))\n",
        "# print(len(uqfilenames[unique_sign_indices]))\n",
        "# print(unique_sign_indices)\n",
        "\n",
        "def uqdelete(j, a):\n",
        "  b = np.copy(a)\n",
        "  assert j >= 0\n",
        "  if b[j]:\n",
        "    b[j] = False\n",
        "  else:\n",
        "    b = uqdelete(j-1, a)\n",
        "  assert(len(np.shape(b)) == 1)\n",
        "  return b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAgPkrBweDpk",
        "outputId": "bdf6b5b9-ef5b-48a3-a2c6-90b2e3366a38"
      },
      "source": [
        "def inputgen(n = 1000, p = 0.5, preds = pred_dataset, gts = gt_dataset):\n",
        "  idxs = np.arange(preds.__len__())\n",
        "  \n",
        "  inputs = []\n",
        "  matches = []\n",
        "\n",
        "  for i in range(n):\n",
        "    match = (np.random.uniform() < p)\n",
        "    j = np.random.choice(idxs)\n",
        "    uqi = np.copy(unique_sign_indices)\n",
        "    \n",
        "    uqi = uqdelete(j, uqi)\n",
        "    #print(np.shape(idxs[uqi]))\n",
        "    k = np.random.choice(idxs[uqi])\n",
        "\n",
        "    #assert j != k and math.floor(float(uqfilenames[j])) != math.floor(float(uqfilenames[k])), f\"J=K: {j}, {k}\"\n",
        "\n",
        "    gt_part = gts.__getitem__(j)[1][:50]\n",
        "    \n",
        "    gt_padlen = 50 - len(gt_part)\n",
        "    if gt_padlen > 0:\n",
        "      gt_padding = np.zeros([gt_padlen, np.shape(gt_part)[1]])\n",
        "      gt_part = np.concatenate((gt_part, gt_padding))\n",
        "    #assert len(gt_part) == 50\n",
        "\n",
        "    if match:\n",
        "      matches.append(1)\n",
        "      pred_part = preds.__getitem__(j)[1][:100]\n",
        "    else:\n",
        "      matches.append(0)\n",
        "      pred_part = preds.__getitem__(k)[1][:100]\n",
        "\n",
        "    pred_padlen = 100 - len(pred_part)\n",
        "    if pred_padlen > 0:\n",
        "      pred_padding = np.zeros([pred_padlen, np.shape(pred_part)[1]])\n",
        "      pred_part = np.concatenate((pred_part, pred_padding))\n",
        "    #assert len(pred_part) == 100\n",
        "\n",
        "    image = np.reshape(np.concatenate((pred_part, gt_part)), -1)\n",
        "    inputs.append(image)\n",
        "\n",
        "  return inputs, matches\n",
        "\n",
        "X, Y = inputgen(p = 0.5, n = 10000)\n",
        "assert len(X) == len(Y)\n",
        "print(f'Inputs: {np.shape(X)}')\n",
        "print(f'Average Match: {np.average(Y)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inputs: (10000, 900)\n",
            "Average Match: 0.5083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q26lL0spu4Vc"
      },
      "source": [
        "#print(X[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUMmtYIYlgQJ"
      },
      "source": [
        "class SGSamples(Dataset):\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(Y)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    xi = X[idx]\n",
        "    yi = Y[idx]\n",
        "\n",
        "    xi = torch.as_tensor(xi, dtype = torch.float )\n",
        "    yi = torch.as_tensor(yi, dtype = torch.long )\n",
        "\n",
        "    sample = {'image': xi, 'label': yi}\n",
        "\n",
        "    return xi, yi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Advg5ZPusE3y"
      },
      "source": [
        "batch_size = 100\n",
        "train_frac = 0.9\n",
        "\n",
        "ttpp = int(train_frac * len(X)) #train-test partition point\n",
        "\n",
        "X_train, X_test = X[:ttpp], X[ttpp:]\n",
        "Y_train, Y_test = Y[:ttpp], Y[ttpp:]\n",
        "\n",
        "train_samples = SGSamples(X=X_train, Y=Y_train)\n",
        "test_samples = SGSamples(X=X_test, Y=Y_test)\n",
        "\n",
        "train_dataloader = DataLoader(train_samples, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_samples, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ2oOMRHtiUP",
        "outputId": "f5551a49-0691-4e84-bdbd-08a41f6d50d6"
      },
      "source": [
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "print(train_labels.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature batch shape: torch.Size([100, 900])\n",
            "Labels batch shape: torch.Size([100])\n",
            "torch.int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDvSoAGNwrer"
      },
      "source": [
        "#Training Hyperparams\n",
        "\n",
        "learning_rate = 1e-3\n",
        "epochs = 20\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyMBK_4lzWXp",
        "outputId": "fbffc1bf-2e26-464e-b631-d3e31009247a"
      },
      "source": [
        "rp = model(train_features.to(device))\n",
        "rt = train_labels.to(device)\n",
        "\n",
        "loss_fn(rp, rt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0180, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHfeEGlWx5Jc"
      },
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X.to(device))\n",
        "        loss = loss_fn(pred, y.to(device))\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 20 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X.to(device))\n",
        "            test_loss += loss_fn(pred, y.to(device)).item()\n",
        "            correct += (pred.argmax(1) == y.to(device)).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV-iyxKjyVsN",
        "outputId": "cf6e177b-f551-4d18-f32a-e95e3e170b04"
      },
      "source": [
        "print(f\"Init: \\n-------------------------------\")\n",
        "\n",
        "test_loop(test_dataloader, model.to(device), loss_fn)\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model.to(device), loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model.to(device), loss_fn)\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Init: \n",
            "-------------------------------\n",
            "Test Error: \n",
            " Accuracy: 52.0%, Avg loss: 0.009266 \n",
            "\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.881502  [    0/10000]\n",
            "loss: 0.604817  [ 2000/10000]\n",
            "loss: 0.504401  [ 4000/10000]\n",
            "loss: 0.430798  [ 6000/10000]\n",
            "loss: 0.378260  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 87.1%, Avg loss: 0.003891 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.393822  [    0/10000]\n",
            "loss: 0.349086  [ 2000/10000]\n",
            "loss: 0.381006  [ 4000/10000]\n",
            "loss: 0.332652  [ 6000/10000]\n",
            "loss: 0.324324  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 86.0%, Avg loss: 0.003202 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.332442  [    0/10000]\n",
            "loss: 0.283394  [ 2000/10000]\n",
            "loss: 0.240634  [ 4000/10000]\n",
            "loss: 0.231948  [ 6000/10000]\n",
            "loss: 0.189712  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 90.9%, Avg loss: 0.002463 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.246304  [    0/10000]\n",
            "loss: 0.465294  [ 2000/10000]\n",
            "loss: 0.179143  [ 4000/10000]\n",
            "loss: 0.212057  [ 6000/10000]\n",
            "loss: 0.157496  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 95.1%, Avg loss: 0.001950 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.208217  [    0/10000]\n",
            "loss: 0.155597  [ 2000/10000]\n",
            "loss: 0.144630  [ 4000/10000]\n",
            "loss: 0.140313  [ 6000/10000]\n",
            "loss: 0.199379  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 96.7%, Avg loss: 0.001455 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 0.143948  [    0/10000]\n",
            "loss: 0.106735  [ 2000/10000]\n",
            "loss: 0.142928  [ 4000/10000]\n",
            "loss: 0.144950  [ 6000/10000]\n",
            "loss: 0.201286  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 97.2%, Avg loss: 0.001126 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 0.103931  [    0/10000]\n",
            "loss: 0.113220  [ 2000/10000]\n",
            "loss: 0.117588  [ 4000/10000]\n",
            "loss: 0.111474  [ 6000/10000]\n",
            "loss: 0.091407  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 98.9%, Avg loss: 0.000961 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.094487  [    0/10000]\n",
            "loss: 0.099516  [ 2000/10000]\n",
            "loss: 0.098225  [ 4000/10000]\n",
            "loss: 0.141359  [ 6000/10000]\n",
            "loss: 0.065510  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 97.0%, Avg loss: 0.000926 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.083526  [    0/10000]\n",
            "loss: 0.063601  [ 2000/10000]\n",
            "loss: 0.334788  [ 4000/10000]\n",
            "loss: 0.093780  [ 6000/10000]\n",
            "loss: 0.062140  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.2%, Avg loss: 0.000655 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.052946  [    0/10000]\n",
            "loss: 0.090728  [ 2000/10000]\n",
            "loss: 0.055784  [ 4000/10000]\n",
            "loss: 0.044336  [ 6000/10000]\n",
            "loss: 0.047507  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.0%, Avg loss: 0.000557 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 0.051401  [    0/10000]\n",
            "loss: 0.072963  [ 2000/10000]\n",
            "loss: 0.042096  [ 4000/10000]\n",
            "loss: 0.055375  [ 6000/10000]\n",
            "loss: 0.047117  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.1%, Avg loss: 0.000493 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 0.073787  [    0/10000]\n",
            "loss: 0.051529  [ 2000/10000]\n",
            "loss: 0.045339  [ 4000/10000]\n",
            "loss: 0.038441  [ 6000/10000]\n",
            "loss: 0.047903  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.7%, Avg loss: 0.000432 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 0.035497  [    0/10000]\n",
            "loss: 0.058120  [ 2000/10000]\n",
            "loss: 0.066379  [ 4000/10000]\n",
            "loss: 0.036391  [ 6000/10000]\n",
            "loss: 0.030342  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.8%, Avg loss: 0.000428 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 0.049872  [    0/10000]\n",
            "loss: 0.040434  [ 2000/10000]\n",
            "loss: 0.041515  [ 4000/10000]\n",
            "loss: 0.038025  [ 6000/10000]\n",
            "loss: 0.028416  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.6%, Avg loss: 0.000322 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.045468  [    0/10000]\n",
            "loss: 0.047497  [ 2000/10000]\n",
            "loss: 0.022494  [ 4000/10000]\n",
            "loss: 0.053572  [ 6000/10000]\n",
            "loss: 0.019393  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.6%, Avg loss: 0.000300 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 0.029943  [    0/10000]\n",
            "loss: 0.025024  [ 2000/10000]\n",
            "loss: 0.022747  [ 4000/10000]\n",
            "loss: 0.043880  [ 6000/10000]\n",
            "loss: 0.033979  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.5%, Avg loss: 0.000275 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 0.028636  [    0/10000]\n",
            "loss: 0.034660  [ 2000/10000]\n",
            "loss: 0.021954  [ 4000/10000]\n",
            "loss: 0.027394  [ 6000/10000]\n",
            "loss: 0.027359  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.8%, Avg loss: 0.000261 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.024678  [    0/10000]\n",
            "loss: 0.015026  [ 2000/10000]\n",
            "loss: 0.022554  [ 4000/10000]\n",
            "loss: 0.014972  [ 6000/10000]\n",
            "loss: 0.052078  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.5%, Avg loss: 0.000250 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.015870  [    0/10000]\n",
            "loss: 0.023218  [ 2000/10000]\n",
            "loss: 0.028837  [ 4000/10000]\n",
            "loss: 0.013641  [ 6000/10000]\n",
            "loss: 0.022962  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.8%, Avg loss: 0.000285 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 0.033475  [    0/10000]\n",
            "loss: 0.011322  [ 2000/10000]\n",
            "loss: 0.030800  [ 4000/10000]\n",
            "loss: 0.016947  [ 6000/10000]\n",
            "loss: 0.020544  [ 8000/10000]\n",
            "Test Error: \n",
            " Accuracy: 99.9%, Avg loss: 0.000294 \n",
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjwgbVV93j5N"
      },
      "source": [
        "def nonrandom_inputgen(j, k, preds = pred_dataset, gts = gt_dataset):\n",
        "\n",
        "  gt_part = gts.__getitem__(k)[1][:50]\n",
        "  \n",
        "  gt_padlen = 50 - len(gt_part)\n",
        "  if gt_padlen > 0:\n",
        "    gt_padding = np.zeros([gt_padlen, np.shape(gt_part)[1]])\n",
        "    gt_part = np.concatenate((gt_part, gt_padding))\n",
        "  #assert len(gt_part) == 50\n",
        "\n",
        "  pred_part = preds.__getitem__(j)[1][:100]\n",
        "\n",
        "  pred_padlen = 100 - len(pred_part)\n",
        "  if pred_padlen > 0:\n",
        "    pred_padding = np.zeros([pred_padlen, np.shape(pred_part)[1]])\n",
        "    pred_part = np.concatenate((pred_part, pred_padding))\n",
        "  #assert len(pred_part) == 100\n",
        "\n",
        "  image = np.reshape(np.concatenate((pred_part, gt_part)), -1)\n",
        "\n",
        "  match = int(j==k)\n",
        "\n",
        "  return image, match\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYvS3R5W1CoT",
        "outputId": "8deddd41-40d4-4ec6-adb3-ffae2a77e16c"
      },
      "source": [
        "model.eval()\n",
        "j = 13\n",
        "k = 0\n",
        "i, m = nonrandom_inputgen(j,k)\n",
        "i = torch.as_tensor([i], dtype=torch.float32)\n",
        "\n",
        "result = nn.Softmax(dim=1)(model(i.to(device))).detach().cpu()\n",
        "print(f'J={j}, K={k}: Guess = {torch.argmax(result)}, Correct = {m} ({result.tolist()[0],})')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "J=13, K=0: Guess = 0, Correct = 0 (([0.9989519119262695, 0.0010481072822585702],))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "326f1KeYlLy6"
      },
      "source": [
        "def notsame(j,k):\n",
        "  val = (j != k and math.floor(float(uqfilenames[j])) != math.floor(float(uqfilenames[k])))\n",
        "  return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYJTUbfcGvD-"
      },
      "source": [
        "#print(np.stack((uqfilenames, range(len(uqfilenames))),axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l15XkzG_EOul"
      },
      "source": [
        "#Useful indices: 2 = an/DINGIR; 8 = ÌR/ARAD; 9 = ÌR, v2; 4,5 = similar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0Io4hzEHW_0"
      },
      "source": [
        "# def sgplot(j,k):\n",
        "  \n",
        "#   fig,ax = plt.subplots(1,2, figsize = [20,10])\n",
        "#   # ax[0].axis('off')\n",
        "#   # ax[1].axis('off')\n",
        "#   plt.show()\n",
        "\n",
        "# sgplot(4,5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}